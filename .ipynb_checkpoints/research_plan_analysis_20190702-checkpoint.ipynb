{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djinn/.local/lib/python3.5/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9797540307044983\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import MeCab\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "\n",
    "# word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('./dataset/model.vec', binary=False)\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('./dataset/entity_vector.model.bin', binary=True)\n",
    "# word2vec_model = gensim.models.Word2Vec.load('./dataset/ja.bin')\n",
    "# word2vec_model = gensim.models.Word2Vec.load('./dataset/entity_vector.model.bin')\n",
    "\n",
    "# mecab = MeCab.Tagger(\"-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd -Owakati\")\n",
    "# mecab = MeCab.Tagger(\"-d /var/lib/mecab/dic/ipadic-utf8 -Owakati\")\n",
    "mecab = MeCab.Tagger(\"-d /var/lib/mecab/dic/ipadic-utf8\")\n",
    "# mecab = MeCab.Tagger(\"\")\n",
    "\n",
    "def avg_feature_vector(sentence, model, num_features):\n",
    "    words = mecab.parse(sentence).replace(' \\n', '').split() \n",
    "    feature_vec = np.zeros((num_features,), dtype=\"float32\") \n",
    "    for word in words:\n",
    "        try:\n",
    "            feature_vec = np.add(feature_vec, model[word])\n",
    "        except KeyError:\n",
    "            print(\"There is no key: \" + word)\n",
    "    if len(words) > 0:\n",
    "        feature_vec = np.divide(feature_vec, len(words))\n",
    "    return feature_vec\n",
    "\n",
    "# ２つの文章の類似度を算出\n",
    "def sentence_similarity(sentence_1, sentence_2):\n",
    "    \n",
    "    # num_features=300\n",
    "    num_features = 200\n",
    "    sentence_1_avg_vector = avg_feature_vector(sentence_1, word2vec_model, num_features)\n",
    "    sentence_2_avg_vector = avg_feature_vector(sentence_2, word2vec_model, num_features)\n",
    "    return 1 - spatial.distance.cosine(sentence_1_avg_vector, sentence_2_avg_vector)\n",
    "\n",
    "result = sentence_similarity(\n",
    "    \"彼は昨日、激辛ラーメンを食べてお腹を壊した\",\n",
    "    \"昨日、僕も激辛の中華料理を食べてお腹を壊した\"\n",
    ")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no key: （\n",
      "There is no key: ）\n",
      "There is no key: （\n",
      "There is no key: ）\n",
      "There is no key: （\n",
      "There is no key: ）\n",
      "There is no key: （\n",
      "There is no key: ）\n",
      "There is no key: （\n",
      "There is no key: ）\n",
      "There is no key: （\n",
      "There is no key: ）\n",
      "There is no key: （\n",
      "There is no key: ）\n",
      "ｎ角形の内角の和を求める式は、（ｎー２）×１８０\n",
      "0.9636648893356323\n",
      "正ｎ角形の一つの内角の大きさを求める式は、（ｎー２）×１８０／ｎ\n",
      "0.873993456363678\n",
      "これに分数、例えば５／２を代入すると、５／２角形の内角の和は（５／２ー２）×１８０＝９０°\n",
      "0.9505108594894409\n",
      "正５／２角形の一つの内角の大きさは、９０／（５／２）＝３６°\n",
      "0.6736023426055908\n",
      "これを元に１角３６°で正多角形を描くと、①のような五ほう星ができる\n",
      "0.8946247100830078\n",
      "７／２なら、②のような図形ができる\n",
      "0.6550813317298889\n",
      "そういった事を知って、興味をもった事が動機\n",
      "0.8473156094551086\n",
      "これらは求めた角度から描いた物なので、こういった分数角形の定義を、整数の多角形と同じような形ではっきりさせたい\n",
      "nan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"./dataset/H29_hakase.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    data = [row for row in reader]\n",
    "\n",
    "student_id = 4\n",
    "sentences = data[student_id][9].split(\"。\")\n",
    "\n",
    "sim_vec = []\n",
    "for i in range(0, len(sentences)-1):\n",
    "    sentence0 = sentences[i]\n",
    "    sentence1 = sentences[i + 1]\n",
    "    \n",
    "    words0 = mecab.parse(sentence0).replace(' \\n', '').split() \n",
    "    words1 = mecab.parse(sentence1).replace(' \\n', '').split()\n",
    "    sim_val = sentence_similarity(sentence0, sentence1)\n",
    "    sim_vec.append(sim_val) \n",
    "# print(sim_vec)\n",
    "    \n",
    "print(sentences[0])\n",
    "for i in range(0, len(sentences)-1):\n",
    "    print(sim_vec[i])\n",
    "    print(sentences[i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
